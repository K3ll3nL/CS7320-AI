{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing Dots and Boxes\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 100, graduate students 110\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play the game Dots and Boxes:\n",
    "\n",
    "> \"Dots and Boxes is a pencil-and-paper game for two players. The game starts with an empty grid of dots. Usually two players take turns adding a single horizontal or vertical line between two unjoined adjacent dots. A player who completes the fourth side of a 1x1 box earns one point and takes another turn. A point is typically recorded by placing a mark that identifies the player in the box, such as an initial. The game ends when no more lines can be placed. The winner is the player with the most points. The board may be of any size grid.\" (see [Dots and Boxes on Wikipedia](https://en.wikipedia.org/wiki/Dots_and_Boxes))\n",
    "\n",
    "You can play Dots and Boxes [here](https://www.math.ucla.edu/~tom/Games/dots&boxes.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [10 point]\n",
    "\n",
    "Define the components of the search problem associated with this game:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Test for the terminal state\n",
    "* Utility for terminal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [30 point]\n",
    "\n",
    "You need to think about a data structure to represent the board meaning he placed lines and who finished what box. There are many options. Let's represent the board using a simple dictionary where `n` and `m` represents the number of dots horizontaly and vertically, respectively. Everybody needs to use the same representation so we can let agents play against each other later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "{'n': 4, 'm': 4, ('h', 1, 1): True, ('v', 1, 1): True}\n",
      "{'n': 4, 'm': 4}\n"
     ]
    }
   ],
   "source": [
    "board2 = {\n",
    "    'n': 4, ### hoizontal dots\n",
    "    'm': 4 ### vertical dots\n",
    "}\n",
    "def draw_line(board, orientation, row, col):\n",
    "    \"\"\"\n",
    "    Place a line on an exiting board.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    board: dict\n",
    "    the board\n",
    "    orientation: str\n",
    "    either 'h' or 'v' for horizontal or vertical\n",
    "    row, col: int\n",
    "    index of the starting dot for the line (starting with 0)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if orientation not in ['h', 'v']:\n",
    "        return False\n",
    "\n",
    "    if row < 0 or col < 0:\n",
    "        return False\n",
    "    if (row >= (board['n'] - 1) and (orientation == 'v')) or (col >= (board['m']-1) and (orientation == 'h')) or (orientation, row, col) in board:\n",
    "        return False\n",
    "    board[(orientation, row, col)] = True\n",
    "    return True\n",
    "\n",
    "def reset_board(board):\n",
    "    newboard = {key:val for key,val in board.items() if val != True}\n",
    "    return newboard\n",
    "\n",
    "print(draw_line(board2, \"h\", 1, 1))\n",
    "print(draw_line(board2, \"v\", 1, 1))\n",
    "print(board2)\n",
    "board2=reset_board(board2)\n",
    "print(board2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write code to display the board. **Bonus point: Post your visualization code with an example output to the discussion board. The best visualization will earn you bonus participation points in this class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# using visualization code posted by Edward Jiang\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import math\n",
    "import random\n",
    "def show_board(board, score):\n",
    "    # here is my code to show board\n",
    "    # black is the background color, number as 0\n",
    "    # blue is the dot color, number as 1\n",
    "    # orange is the line color, number as 2\n",
    "    # we assume the dots are 0 indexed, aka starts at 0\n",
    "    cmap = colors.ListedColormap(['black', 'blue','orange',\"red\",\"yellow\"])\n",
    "    hdot = board[\"n\"]\n",
    "    vdot = board[\"m\"]\n",
    "    # get vertical and horizontal size\n",
    "    np_board = np.zeros( (hdot + (hdot-1)*3, vdot + (vdot-1)*3) , dtype=np.int64)\n",
    "    # convert the board to an np matrix\n",
    "    # we assume each dot is size of 1, each line occupies 3 index\n",
    "    for i in range(np_board.shape[0]):\n",
    "        if i%4==0:\n",
    "            for j in range(np_board.shape[1]):\n",
    "                if j%4==0:\n",
    "                    np_board[i][j] = 1\n",
    "    # all divisor of 4 is a dot\n",
    "    for key in board:\n",
    "    # draw lines\n",
    "        if key != \"n\" and key !=\"m\" and key:\n",
    "    # print(key)\n",
    "            if key[0] ==\"h\":\n",
    "    # print(\"horizontal line\")\n",
    "                for idx in range(key[2]*4+1, key[2]*4+4):\n",
    "                    np_board[key[1]*4][idx] =2\n",
    "            elif key[0] ==\"v\":\n",
    "    # print(\"vertical line\")\n",
    "                for idx in range(key[1]*4+1, key[1]*4+4):\n",
    "                    np_board[idx][key[2]*4] =2\n",
    "\n",
    "        else:\n",
    "            print(\"not known\")\n",
    "    # draw squares by players\n",
    "    # score is a dict with p1 and p2 as keys and list of occupied squares (int) as values\n",
    "    # the squares are also zeroth index\n",
    "    # for example, in a 3x3 board we will have\n",
    "    # 0 1 2\n",
    "    # 3 4 5\n",
    "    # 6 7 8\n",
    "    score_p1 = score[\"p1\"]\n",
    "    score_p2 = score[\"p2\"]\n",
    "    for idx in score_p1:\n",
    "        row = idx// (hdot-1)*4+1\n",
    "        col = idx% (vdot-1)*4+1\n",
    "        for l in range(row,row+3):\n",
    "            for k in range(col, col+3):\n",
    "                np_board[l][k]=3\n",
    "    for idx in score_p2:\n",
    "        row = idx// (hdot-1)*4+1\n",
    "        col = idx% (vdot-1)*4+1\n",
    "        for l in range(row,row+3):\n",
    "            for k in range(col, col+3):\n",
    "                np_board[l][k]=4\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(np_board, cmap = cmap, norm = colors.BoundaryNorm(list(range(cmap.N + 1)), cmap.N))\n",
    "    plt.show()\n",
    "# display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "not known\n",
      "not known\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': 4, 'm': 4, ('h', 1, 1): False, ('v', 1, 1): False, ('v', 2, 1): False, ('h', 2, 0): False, ('v', 2, 3): False, ('h', 2, 1): False, ('h', 0, 2): False, ('v', 0, 3): False, ('h', 1, 2): False, ('h', 0, 0): False, ('h', 1, 0): False, ('h', 3, 1): False, ('h', 3, 2): False, ('h', 3, 0): False, ('h', 2, 2): False, ('v', 0, 0): False, ('v', 2, 0): False, ('v', 1, 3): False, ('v', 2, 2): False, ('v', 0, 2): False, ('v', 0, 1): False, ('v', 1, 0): False, ('v', 1, 2): False, ('h', 0, 1): False} False\n"
     ]
    }
   ],
   "source": [
    "# score = {\"p1\":[],\"p2\":[4]}\n",
    "reset_board(board2)\n",
    "for i in range(7):\n",
    "    print(draw_line(board2, np.random.choice([\"v\",\"h\"]), random.randrange(board2[\"n\"]), random.randrange(board2[\"m\"])))\n",
    "show_board(board2, {\"p1\":[],\"p2\":[]})\n",
    "print(board2,board2[('h',0,1)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "reset_board(board2)\n",
    "for tuple in board2:\n",
    "    print(board2[tuple])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "not known\n",
      "not known\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(draw_line(board2, \"v\", 0, 3))\n",
    "score = {\"p1\":[2],\"p2\":[4]}\n",
    "show_board(board2,score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* The transition model $result(s, a)$.\n",
    "* The utility function $utility(s)$.\n",
    "* Check for terminal states $terminal(s)$.\n",
    "* A check for available actions in each state $actions(s)$.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes (number of columns and rows as stored in the board)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "import copy\n",
    "from copy import deepcopy\n",
    "\n",
    "def result(board,player,move,score):\n",
    "    new_copy = copy.deepcopy(board)\n",
    "    new_score = copy.deepcopy(score)\n",
    "    draw_line(new_copy,move[0],move[1],move[2])\n",
    "    calcScore(new_copy,player,new_score)\n",
    "    return new_copy,new_score\n",
    "\n",
    "def isTerminal(board):\n",
    "    for i in range(0,board[\"m\"]):\n",
    "        for j in range(0,board[\"n\"]):\n",
    "            if board[\"v\", i, j] or board[\"h\", i, j]:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def isWin(board,player,score):\n",
    "    if not isTerminal(board):\n",
    "        return \"Not a terminal state\"\n",
    "    if len(score[\"p1\"]) == len(score[\"p2\"]):\n",
    "        return \"Draw\"\n",
    "    if len(score[player]) > len(score[\"p2\" if player==\"p1\" else \"p1\"]):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def util(board,player,score):\n",
    "    outcome = isWin(board,player,score)\n",
    "    if outcome == \"Draw\":\n",
    "        return 0\n",
    "    return 1 if outcome else -1\n",
    "\n",
    "\n",
    "def actions(board):\n",
    "    actions = []\n",
    "    for i in range(0,board[\"n\"]):\n",
    "        for j in range(0,board[\"m\"]):\n",
    "            if board[\"v\", i, j]:\n",
    "                actions.append((\"v\",i,j))\n",
    "            if board[\"h\", i, j]:\n",
    "                actions.append((\"h\",i,j))\n",
    "    return actions\n",
    "\n",
    "\n",
    "def calcScore(board,currPlayer,score):\n",
    "    current = currPlayer\n",
    "    num_dot = 0\n",
    "    for i in range(0,board[\"n\"]-1):\n",
    "        for j in range(0,board[\"m\"]-1):\n",
    "            if not board[\"h\", i, j] and not board[\"v\", i, j] and not board[\"h\", i + 1, j] and not board[\"v\", i, j + 1]:\n",
    "                if num_dot not in score[\"p1\"] and num_dot not in score[\"p2\"]:\n",
    "                    score[current].append(num_dot)\n",
    "            num_dot = num_dot + 1\n",
    "    return None\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = None): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what side they are playing. The value passed on bt yhe environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_player(board, player,score):\n",
    "    possibleMoves = actions(board)\n",
    "    action = random.choice(possibleMoves)\n",
    "\n",
    "    return action,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "def my_environment(player1,player2,rows,cols,score):\n",
    "    board = {\n",
    "        'n': rows, ### hoizontal dots\n",
    "        'm': cols ### vertical dots\n",
    "    }\n",
    "\n",
    "\n",
    "    currPlayer = \"p1\"\n",
    "    while isTerminal(board) != True:\n",
    "        scoreBeforeTurn = len(score[currPlayer])\n",
    "        currAgent = player1 if currPlayer==\"p1\" else player2\n",
    "\n",
    "        action = currAgent(board,currPlayer,score)\n",
    "        move = action[0]\n",
    "        draw_line(board,move[0],move[1],move[2])\n",
    "        calcScore(board,currPlayer,score)\n",
    "        newScore = len(score[currPlayer])\n",
    "        if newScore == scoreBeforeTurn:\n",
    "            currPlayer = \"p2\" if currPlayer==\"p1\" else \"p1\"\n",
    "        else:\n",
    "            currPlayer = currPlayer\n",
    "    show_board(board,score)\n",
    "    outcome = isWin(board,\"p1\",score)\n",
    "    return outcome\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('v', 0, 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "\u001B[1;32mC:\\Users\\KELLEN~1\\AppData\\Local\\Temp/ipykernel_28200/951224039.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mscore\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;34m\"p1\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;34m\"p2\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0moutcome\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmy_environment\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrandom_player\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mrandom_player\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutcome\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\KELLEN~1\\AppData\\Local\\Temp/ipykernel_28200/1330175820.py\u001B[0m in \u001B[0;36mmy_environment\u001B[1;34m(player1, player2, rows, cols, score)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0mcurrPlayer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"p1\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 9\u001B[1;33m     \u001B[1;32mwhile\u001B[0m \u001B[0misTerminal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mboard\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m!=\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m         \u001B[0mscoreBeforeTurn\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mscore\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mcurrPlayer\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m         \u001B[0mcurrAgent\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mplayer1\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mcurrPlayer\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;34m\"p1\"\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mplayer2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\Users\\KELLEN~1\\AppData\\Local\\Temp/ipykernel_28200/3815346805.py\u001B[0m in \u001B[0;36misTerminal\u001B[1;34m(board)\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mboard\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"m\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mj\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mboard\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"n\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m             \u001B[1;32mif\u001B[0m \u001B[0mboard\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"v\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mboard\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"h\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mj\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: ('v', 0, 0)"
     ]
    }
   ],
   "source": [
    "score = {\"p1\":[],\"p2\":[]}\n",
    "outcome = my_environment(random_player,random_player,4,4,score)\n",
    "print(outcome)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wins = 0\n",
    "losses = 0\n",
    "draw = 0\n",
    "for i in range(0,1000):\n",
    "    score = {\"p1\":[],\"p2\":[]}\n",
    "    outcome = my_environment(random_player,random_player,4,4,score)\n",
    "    if outcome:\n",
    "        wins = wins + 1\n",
    "    if not outcome:\n",
    "        losses = losses + 1\n",
    "    if outcome == \"Draw\":\n",
    "        draw = draw + 1\n",
    "print(\"Wins:\", wins, \"Losses:\", losses, \"Draw:\", draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [30 points]\n",
    "\n",
    "### Implement the search starting.\n",
    "\n",
    "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
    "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "\n",
    "__Notes:__ \n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
    "* The search space for larger board may be too large. You can experiment with smaller boards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "def alpha_beta_search(board, player,score):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "\n",
    "\n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf,score)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"Number of nodes searched: {COUNT}\")\n",
    "\n",
    "    return move, value\n",
    "def max_value_ab(state, player, alpha, beta,score):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "    #print(player)\n",
    "    #print(score)\n",
    "    v = util(state, player,score)\n",
    "    if DEBUG >= 2: print(f\"max: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    if v is not None:\n",
    "        if DEBUG >= 2: print(f\" found terminal state. backtracking.\")\n",
    "    return v, None\n",
    "\n",
    "    v, move = -math.inf, None\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        new_state = result(state, player, a,score)\n",
    "\n",
    "    v2, a2 = min_value_ab(new_state[0], player, alpha, beta,new_state[1])\n",
    "\n",
    "    if DEBUG >= 2: print(f\"max: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 > v:\n",
    "        v, move = v2, a\n",
    "    alpha = max(alpha, v)\n",
    "    if v >= beta:\n",
    "        if DEBUG >= 2: print(f\" v>=beta ({v}>={beta}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move\n",
    "\n",
    "    return v, move\n",
    "def min_value_ab(state, player, alpha, beta,score):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "\n",
    "    v = util(state, player,score)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"min: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    if v is not None:\n",
    "        if DEBUG >= 2: print(f\" found terminal state. backtacking.\")\n",
    "    return v, None\n",
    "\n",
    "    v, move = +math.inf, None\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actionsctions(state):\n",
    "    #print(player,'in min')\n",
    "\n",
    "    new_state = result(state, other(player), a,score)\n",
    "\n",
    "    v2, a2 = max_value_ab(new_state[0], player, alpha, beta,new_state[1])\n",
    "    if DEBUG >= 2: print(f\"min: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 < v:\n",
    "        v, move = v2, a\n",
    "    beta = min(beta, v)\n",
    "    if v <= alpha:\n",
    "        if DEBUG >= 2: print(f\" v<=alpha ({v}<={alpha}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds move to tie\n",
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[0],\"p2\":[2,3]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "draw_line(board,\"v\",1,2)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"v\",0,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"h\",2,0)\n",
    "show_board(board,score)\n",
    "test = checkTerminal(board)\n",
    "print(test)\n",
    "print()\n",
    "%time display(alpha_beta_search(board,\"p1\",score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#finds winning move\n",
    "testBoard = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[2,1],\"p2\":[0]}\n",
    "draw_line(testBoard,\"v\",1,0)\n",
    "draw_line(testBoard,\"h\",2,0)\n",
    "draw_line(testBoard,\"v\",1,1)\n",
    "draw_line(testBoard,\"h\",1,0)\n",
    "draw_line(testBoard,\"h\",0,0)\n",
    "draw_line(testBoard,\"v\",0,0)\n",
    "draw_line(testBoard,\"v\",0,1)\n",
    "draw_line(testBoard,\"v\",0,2)\n",
    "draw_line(testBoard,\"v\",1,2)\n",
    "draw_line(testBoard,\"h\",0,1)\n",
    "draw_line(testBoard,\"h\",1,1)\n",
    "show_board(testBoard,score)\n",
    "print()\n",
    "%time display(alpha_beta_search(testBoard,\"p1\",score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[3],\"p2\":[2]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"v\",1,2)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"h\",2,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"h\",2,0)\n",
    "draw_line(board,\"v\",0,2)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_search(board,\"p1\",score)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#finds tying move\n",
    "board = {\n",
    "'n': 3, ### hoizontal dots\n",
    "'m': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[0,1],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"v\",0,1)\n",
    "draw_line(board,\"v\",0,2)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_search(board,\"p2\",score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#finds winning move for p2\n",
    "testBoard = {\n",
    "'n': 3, ### hoizontal dots\n",
    "'m': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[3],\"p2\":[1]}\n",
    "draw_line(testBoard,\"v\",1,0)\n",
    "draw_line(testBoard,\"h\",2,0)\n",
    "draw_line(testBoard,\"v\",1,1)\n",
    "draw_line(testBoard,\"h\",0,0)\n",
    "draw_line(testBoard,\"v\",0,0)\n",
    "draw_line(testBoard,\"v\",0,1)\n",
    "draw_line(testBoard,\"v\",0,2)\n",
    "draw_line(testBoard,\"v\",1,2)\n",
    "draw_line(testBoard,\"h\",0,1)\n",
    "draw_line(testBoard,\"h\",1,1)\n",
    "draw_line(testBoard,\"h\",2,1)\n",
    "show_board(testBoard,score)\n",
    "print()\n",
    "%time display(alpha_beta_search(testBoard,\"p2\",score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board make the board larger. What is the largest board you can solve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testval = 2\n",
    "testBoard = {\n",
    "'n': testval, ### hoizontal dots\n",
    "'m': testval ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(testBoard,score)\n",
    "print()\n",
    "%time display(alpha_beta_search(testBoard,\"p1\",score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I've decided that moves placed along the edge of the board are better at the start of games. So I will be giving all moves\n",
    "# at the edges of the board a higher priority\n",
    "def orderActions(board):\n",
    "    rows = board[\"n\"]\n",
    "    col = board[\"m\"]\n",
    "    actions = []\n",
    "    testBoard = copy.deepcopy(board)\n",
    "    for i in range(0,rows):\n",
    "        for j in range(0,col):\n",
    "        if(draw_line(testBoard,\"v\",i,j) == True):\n",
    "        actions.append((\"v\",i,j))\n",
    "\n",
    "\n",
    "    if(draw_line(testBoard,\"h\",i,j) == True):\n",
    "        actions.append((\"h\",i,j))\n",
    "\n",
    "    for i in actions:\n",
    "        if i[0] == \"h\":\n",
    "        if i[1] == 0 or i[1] == (rows - 1):\n",
    "        actions.insert(0, actions.pop(actions.index(i)))\n",
    "    if i[0] == \"v\":\n",
    "        if i[2] == 0 or i[2] == (col - 1):\n",
    "\n",
    "    actions.insert(0, actions.pop(actions.index(i)))\n",
    "    # print(actions)\n",
    "    # print('-------')\n",
    "\n",
    "\n",
    "    return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "def alpha_beta_search_move_order(board, player,score):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "\n",
    "\n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf,score)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"Number of nodes searched: {COUNT}\")\n",
    "\n",
    "    return move, value\n",
    "def max_value_ab(state, player, alpha, beta,score):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "    #print(player)\n",
    "    #print(score)\n",
    "    v = util(state, player,score)\n",
    "    if DEBUG >= 2: print(f\"max: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    if v is not None:\n",
    "        if DEBUG >= 2: print(f\" found terminal state. backtracking.\")\n",
    "    return v, None\n",
    "\n",
    "    v, move = -math.inf, None\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in orderActions(state):\n",
    "        new_state = result(state, player, a,score)\n",
    "\n",
    "    v2, a2 = min_value_ab(new_state[0], player, alpha, beta,new_state[1])\n",
    "\n",
    "    if DEBUG >= 2: print(f\"max: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 > v:\n",
    "        v, move = v2, a\n",
    "    alpha = max(alpha, v)\n",
    "    if v >= beta:\n",
    "        if DEBUG >= 2: print(f\" v>=beta ({v}>={beta}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move\n",
    "\n",
    "    return v, move\n",
    "def min_value_ab(state, player, alpha, beta,score):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "\n",
    "    v = util(state, player,score)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"min: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    if v is not None:\n",
    "        if DEBUG >= 2: print(f\" found terminal state. backtacking.\")\n",
    "    return v, None\n",
    "\n",
    "    v, move = +math.inf, None\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in orderActions(state):\n",
    "    #print(player,'in min')\n",
    "\n",
    "    new_state = result(state, other(player), a,score)\n",
    "\n",
    "    v2, a2 = max_value_ab(new_state[0], player, alpha, beta,new_state[1])\n",
    "    if DEBUG >= 2: print(f\"min: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 < v:\n",
    "        v, move = v2, a\n",
    "    beta = min(beta, v)\n",
    "    if v <= alpha:\n",
    "        if DEBUG >= 2: print(f\" v<=alpha ({v}<={alpha}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "show_board(board,score)\n",
    "print()\n",
    "N = 2\n",
    "tm = timeit.timeit('for i in range(2): alpha_beta_search_move_order(board,\"p1\",score)',\n",
    "                   globals = globals(), number = N)\n",
    "timing = tm/N * 1e3\n",
    "orderedActionsList = ['3x3',timing]\n",
    "tm = timeit.timeit('for i in range(2): alpha_beta_search(board,\"p1\",score)',\n",
    "                   globals = globals(), number = N)\n",
    "timing = tm/N * 1e3\n",
    "normalActionsList = ['3x3',timing]\n",
    "array = np.array([normalActionsList, orderedActionsList])\n",
    "index_values = ['normalActionsList', 'orderedActionsList']\n",
    "column_values = ['board size', 'AVG time in milliseconds over 10 runs']\n",
    "df = pd.DataFrame(data = array, index = index_values, columns = column_values)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[0,3],\"p2\":[2]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "draw_line(board,\"v\",1,2)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"v\",0,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"h\",2,0)\n",
    "show_board(board,score)\n",
    "print()\n",
    "N = 2\n",
    "tm = timeit.timeit('for i in range(2): alpha_beta_search_move_order(board,\"p1\",score)',\n",
    "                   globals = globals(), number = N)\n",
    "timing = tm/N * 1e3\n",
    "orderedActionsList = ['3x3',timing]\n",
    "tm = timeit.timeit('for i in range(2): alpha_beta_search(board,\"p1\",score)',\n",
    "                   globals = globals(), number = N)\n",
    "timing = tm/N * 1e3\n",
    "normalActionsList = ['3x3',timing]\n",
    "array = np.array([normalActionsList, orderedActionsList])\n",
    "index_values = ['normalActionsList', 'orderedActionsList']\n",
    "column_values = ['board size', 'AVG time in milliseconds over 10 runs']\n",
    "df = pd.DataFrame(data = array, index = index_values, columns = column_values)\n",
    "print(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search seems to be slightly faster with the move ordering,but not a big enough difference to really matter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I thought it might be a good idea to make random moves if it is one of the first 3 turns of the game. This will save time on the first few turns where descisions arent as important, but will use alpha beta search on the 4th turn which is the first opportunity for box to be completed by either player.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a random move it is within the first 3 turns of the game\n",
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "def alpha_beta_search_random(board, player,score):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    rows = board['n']\n",
    "    cols = board['m']\n",
    "    poss_moves = (rows * cols -rows) + (rows * cols - cols)\n",
    "    num_actions = len(actions(board))\n",
    "    if (num_actions + 2 >= poss_moves):\n",
    "        possibleMoves = actions(board)\n",
    "    action = random.choice(possibleMoves)\n",
    "    return action,None\n",
    "\n",
    "\n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf,score)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"Number of nodes searched: {COUNT}\")\n",
    "\n",
    "    return move, value\n",
    "def max_value_ab(state, player, alpha, beta,score):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "    #print(player)\n",
    "    #print(score)\n",
    "    v = util(state, player,score)\n",
    "    if DEBUG >= 2: print(f\"max: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    if v is not None:\n",
    "        if DEBUG >= 2: print(f\" found terminal state. backtracking.\")\n",
    "    return v, None\n",
    "\n",
    "    v, move = -math.inf, None\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        new_state = result(state, player, a,score)\n",
    "\n",
    "    v2, a2 = min_value_ab(new_state[0], player, alpha, beta,new_state[1])\n",
    "\n",
    "    if DEBUG >= 2: print(f\"max: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 > v:\n",
    "        v, move = v2, a\n",
    "    alpha = max(alpha, v)\n",
    "    if v >= beta:\n",
    "        if DEBUG >= 2: print(f\" v>=beta ({v}>={beta}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move\n",
    "\n",
    "    return v, move\n",
    "def min_value_ab(state, player, alpha, beta,score):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "\n",
    "    v = util(state, player,score)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"min: {state} [alpha,beta]=[{alpha},{beta}] v={v}\")\n",
    "    if v is not None:\n",
    "        if DEBUG >= 2: print(f\" found terminal state. backtacking.\")\n",
    "    return v, None\n",
    "\n",
    "    v, move = +math.inf, None\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "    # print(player,'in min')\n",
    "\n",
    "    new_state = result(state, other(player), a,score)\n",
    "\n",
    "    v2, a2 = max_value_ab(new_state[0], player, alpha, beta,new_state[1])\n",
    "    if DEBUG >= 2: print(f\"min: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 < v:\n",
    "        v, move = v2, a\n",
    "    beta = min(beta, v)\n",
    "    if v <= alpha:\n",
    "        if DEBUG >= 2: print(f\" v<=alpha ({v}<={alpha}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#if its one of the first three turns simply make a random move to save time\n",
    "testBoard = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(testBoard,score)\n",
    "print()\n",
    "%time display(alpha_beta_search_random(testBoard,\"p1\",score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#if its not one of the first 3 turns it will use the alpha beta search to find optimal move\n",
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[0,1],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"v\",0,1)\n",
    "draw_line(board,\"v\",0,2)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_search_random(board,\"p1\",score))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = 0\n",
    "losses = 0\n",
    "draw = 0\n",
    "for i in range(0,100):\n",
    "    score = {\"p1\":[],\"p2\":[]}\n",
    "    outcome = my_environment(alpha_beta_search,random_player,3,3,score)\n",
    "    if(outcome == True):\n",
    "        wins = wins + 1\n",
    "    if(outcome == False):\n",
    "        losses = losses + 1\n",
    "    if(outcome == \"Draw\"):\n",
    "        draw = draw + 1\n",
    "print(\"Wins:\", wins, \"Losses:\", losses, \"Draw:\", draw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [30 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my heuristic function looks at the number of boxes each player has completed and finds the difference. I then divide that\n",
    "# difference by the number of possible boxes for the board\n",
    "def evaluation(board,player,score):\n",
    "    u = util(board, player,score)\n",
    "    if u is not None: return u, True\n",
    "\n",
    "    score_dif = len(score[player]) - len(score[other(player)])\n",
    "    rows = board['n'] -1\n",
    "    cols = board['m'] - 1\n",
    "    poss_boxes = rows * cols\n",
    "    new_util = score_dif/poss_boxes\n",
    "    return new_util, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "testBoard = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[2],\"p2\":[0,1]}\n",
    "draw_line(testBoard,\"v\",1,0)\n",
    "draw_line(testBoard,\"h\",2,0)\n",
    "draw_line(testBoard,\"v\",1,1)\n",
    "draw_line(testBoard,\"h\",1,0)\n",
    "draw_line(testBoard,\"v\",0,0)\n",
    "draw_line(testBoard,\"h\",0,0)\n",
    "draw_line(testBoard,\"v\",0,1)\n",
    "evaluation(testBoard,\"p1\", score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "DEBUG = 1 # 1 ... count nodes, 2 ... debug each node\n",
    "COUNT = 0\n",
    "def alpha_beta_heuristic(board, player,score,cutoff):\n",
    "    \"\"\"start the search.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT = 0\n",
    "    # rows = board['n']\n",
    "    # cols = board['m']\n",
    "    # poss_moves = (rows * cols -rows) + (rows * cols - cols)\n",
    "    # num_actions = len(actions(board))\n",
    "    # if (num_actions + 2 >= poss_moves):\n",
    "    # possibleMoves = actions(board)\n",
    "    # action = random.choice(possibleMoves)\n",
    "    # return action,None\n",
    "\n",
    "\n",
    "    value, move = max_value_ab(board, player, -math.inf, +math.inf,score,0,cutoff)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"Number of nodes searched: {COUNT}\")\n",
    "\n",
    "    return move, value\n",
    "def max_value_ab(state, player, alpha, beta,score,depth,cutoff):\n",
    "    \"\"\"player's best move.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "    #print(player)\n",
    "    #print(score)\n",
    "    v, terminal = evaluation(state, player,score)\n",
    "    if((cutoff is not None and depth >= cutoff) or terminal):\n",
    "        if(terminal):\n",
    "        alpha, beta = v, v\n",
    "    if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" )\n",
    "    return v, None\n",
    "\n",
    "    v, move = -math.inf, None\n",
    "    # check all possible actions in the state, update alpha and return move with the largest value\n",
    "    for a in actions(state):\n",
    "        new_state = result(state, player, a,score)\n",
    "\n",
    "    v2, a2 = min_value_ab(new_state[0], player, alpha, beta,new_state[1],depth +1,cutoff)\n",
    "\n",
    "    if DEBUG >= 2: print(f\"max: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 > v:\n",
    "        v, move = v2, a\n",
    "    alpha = max(alpha, v)\n",
    "    if v >= beta:\n",
    "        if DEBUG >= 2: print(f\" v>=beta ({v}>={beta}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move\n",
    "\n",
    "    return v, move\n",
    "def min_value_ab(state, player, alpha, beta,score,depth,cutoff):\n",
    "    \"\"\"opponent's best response.\"\"\"\n",
    "    global DEBUG, COUNT\n",
    "    COUNT += 1\n",
    "\n",
    "    # return utility of state is a terminal state\n",
    "\n",
    "    v, terminal = evaluation(state, player,score)\n",
    "    if((cutoff is not None and depth >= cutoff) or terminal):\n",
    "        if(terminal):\n",
    "        alpha, beta = v, v\n",
    "    if DEBUG >= 2: print(f\"stopped at {depth}: {state} term: {terminal} eval: {v} [{alpha}, {beta}]\" )\n",
    "    return v, None\n",
    "    v, move = +math.inf, None\n",
    "    # check all possible actions in the state, update beta and return move with the smallest value\n",
    "    for a in actions(state):\n",
    "    #print(player,'in min')\n",
    "\n",
    "    new_state = result(state, other(player), a,score)\n",
    "\n",
    "    v2, a2 = max_value_ab(new_state[0], player, alpha, beta,new_state[1],depth +1,cutoff)\n",
    "    if DEBUG >= 2: print(f\"min: {state} (backtracked) [alpha,beta]=[{alpha},{beta}] v={v2}\")\n",
    "\n",
    "    if v2 < v:\n",
    "        v, move = v2, a\n",
    "    beta = min(beta, v)\n",
    "    if v <= alpha:\n",
    "        if DEBUG >= 2: print(f\" v<=alpha ({v}<={alpha}): pruning remaining subtree (actions). backtracking.\")\n",
    "    return v, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I found a cutoff of 4 was effective and made moves quickly, so I decided to use that"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finds winning move\n",
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[0,3],\"p2\":[2]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "draw_line(board,\"v\",1,2)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"v\",0,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"h\",2,0)\n",
    "show_board(board,score)\n",
    "test = checkTerminal(board)\n",
    "print(test)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#finds move that completes box\n",
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"h\",2,1)\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#finds winning move for p2\n",
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[0],\"p2\":[1,2]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"v\",1,2)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"v\",0,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"h\",2,0)\n",
    "draw_line(board,\"v\",0,2)\n",
    "show_board(board,score)\n",
    "test = checkTerminal(board)\n",
    "print(test)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p2\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[3],\"p2\":[2]}\n",
    "draw_line(board,\"h\",1,1)\n",
    "draw_line(board,\"v\",1,1)\n",
    "draw_line(board,\"v\",1,2)\n",
    "draw_line(board,\"h\",0,0)\n",
    "draw_line(board,\"v\",0,0)\n",
    "draw_line(board,\"h\",1,0)\n",
    "draw_line(board,\"h\",2,1)\n",
    "draw_line(board,\"v\",1,0)\n",
    "draw_line(board,\"h\",0,1)\n",
    "draw_line(board,\"h\",2,0)\n",
    "draw_line(board,\"v\",0,2)\n",
    "show_board(board,score)\n",
    "test = checkTerminal(board)\n",
    "print(test)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p2\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 3, ### hoizontal dots\n",
    "    'm': 3 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 4, ### hoizontal dots\n",
    "    'm': 4 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 5, ### hoizontal dots\n",
    "    'm': 5 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 6, ### hoizontal dots\n",
    "    'm': 6 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 5, ### hoizontal dots\n",
    "    'm': 6 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "board = {\n",
    "    'n': 7, ### hoizontal dots\n",
    "    'm': 7 ### vertical dots\n",
    "}\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "show_board(board,score)\n",
    "print()\n",
    "%time display(alpha_beta_heuristic(board,\"p1\",score,4))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_environment(player1,player2,rows,cols,score):\n",
    "    board = {\n",
    "        'n': rows, ### hoizontal dots\n",
    "        'm': cols ### vertical dots\n",
    "    }\n",
    "\n",
    "\n",
    "    currPlayer = \"p1\"\n",
    "    while(checkTerminal(board) != True):\n",
    "        scoreBeforeTurn = len(score[currPlayer])\n",
    "        isBoxCreated = False\n",
    "        if(currPlayer == \"p1\"):\n",
    "            currAgent = player1\n",
    "            cutoff = 4\n",
    "        else:\n",
    "            currAgent = player2\n",
    "            cutoff = 6\n",
    "\n",
    "        action = currAgent(board,currPlayer,score,cutoff)\n",
    "        #print(action)\n",
    "        move = action[0]\n",
    "        #print(move)\n",
    "        draw_line(board,move[0],move[1],move[2])\n",
    "        getScore(board,currPlayer,score)\n",
    "        newScore = len(score[currPlayer])\n",
    "        if(newScore == scoreBeforeTurn):\n",
    "            if(currPlayer == \"p1\"):\n",
    "                currPlayer = \"p2\"\n",
    "            else:\n",
    "                currPlayer = \"p1\"\n",
    "        else:\n",
    "            currPlayer = currPlayer\n",
    "        show_board(board,score)\n",
    "    outcome = checkWin(board,\"p1\",score)\n",
    "    return outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#p1 has cutoff of 4 and p2 has cutoff of 6\n",
    "score = {\"p1\":[],\"p2\":[]}\n",
    "outcome = new_environment(alpha_beta_heuristic,alpha_beta_heuristic,4,4,score)\n",
    "if(outcome == True):\n",
    "    print(\"p1 wins!\")\n",
    "if(outcome == False):\n",
    "    print(\"p2 wins!\")\n",
    "if(outcome == \"Draw\"):\n",
    "    print(\"Draw!\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tournament task [+1 to 5% bonus on your course grade; will be assigned separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. You are allowed to use any improvements you like as long as you code it yourself. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [10 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+5 Bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search (see [tic-tac-toe-example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_pure_monte_carlo_search.ipynb)) and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move for a standard board ($5 \\times 5$) is? You can use Pure Monte Carlo Search or any algorithms that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}